{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.item {\n",
       "    vertical-align: bottom;\n",
       "    text-align: center;\n",
       "}\n",
       "img {\n",
       "    background-color: white;\n",
       "}\n",
       ".caption {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       "/* Three image containers (use 25% for four, and 50% for two, etc) */\n",
       ".column {\n",
       "  float: left;\n",
       "  width: 50%;\n",
       "  padding: 5px;\n",
       "}\n",
       "\n",
       "/* Clear floats after image containers */\n",
       ".row::after {\n",
       "  content: \"\";\n",
       "  clear: both;\n",
       "  display: table;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "utils.set_css_style('style.css')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bias & Variance\n",
    "\n",
    "Let's look at the following simple example. If you fit a straight line to the data, maybe a simple linear regression, then this is not a very good fit to the data. This is problem of a high bias, we also say that our model is underfitting the data. On the opposite end, if you fit an incredibly complex regressor, maybe a deep neural network, or a neural network with many hidden units, it's possible that you fit the data perfectly, but that doesn't look like a great fit either. So this is called a regressor of high variance and we also say that this model is overfitting the data. A model in between, with a medium level of complexity, fits the data correctly. \n",
    "\n",
    "As mentioned earlier, in machine learning we usually split our data into two subsets: training data and testing data (and sometimes to three: train, validate and test), and fit our model on the train data, in order to make predictions on the test data. When we do that, one of two thing might happen: we overfit our model or we underfit our model. \n",
    "\n",
    "## 2.1. Overfitting\n",
    "\n",
    "**Overfitting** means that model we trained has trained “too well” and is now, well, fit too closely to the training dataset. This is also called a **high variance** problem. This usually happens when the model is too complex (i.e. too many features/variables compared to the number of observations). This model will be very accurate on the training data but will probably be very not accurate on untrained or new data. It is because this model is not generalized and can’t make any inferences on new unseen data, which is, ultimately, what you are trying to do. Basically, when this happens, the model learns the “noise” in the training data instead of the actual relationships between variables in the data.\n",
    "\n",
    "## 2.2. Underfitting\n",
    "\n",
    "In contrast to overfitting, when a model is underfitted, it means that the model does not fit the training data and therefore misses the trends in the data. It also means the model cannot be generalized to new data. As you probably guessed (or figured out!), this is usually the result of a very simple model (not enough predictors/independent variables). It could also happen when, for example, we fit a linear model (like linear regression) to data that is not linear. It almost goes without saying that this model will have poor predictive ability on the training data.\n",
    "\n",
    "<img src=\"figures/bias-variance.png\" alt=\"bias-variance\" style=\"width: 700px;\"/>\n",
    "\n",
    "One way to check if your model is suffering from high bias or high variance is to compare the training error with the validation set error.\n",
    "\n",
    "\n",
    "## 2.3. Bias & variance diagnosis\n",
    "\n",
    "We need to distinguish whether bias or variance is the problem contributing to bad predictions.\n",
    "\n",
    "The training error will tend to decrease as we increase the complexity of the model (for example the degree $d$ of the polynomial of a linear regression model), whereas the validation/test error will tend to decrease as we increase the complexity up to a point, and then it will increase as complexity is increased, forming a convex curve.\n",
    "\n",
    "* **High bias** (underfitting): both $J_{train}(\\theta)$ and $J_{test}(\\theta)$ will be high. Also, $J_{test}(\\theta) \\approx J_{train}(\\theta)$.\n",
    "\n",
    "* **High variance** (overfitting): $J_{train}(\\theta)$ will be low and $J_{test}(\\theta)$ will be much greater than $J_{train}(\\theta)$.\n",
    "\n",
    "The is summarized in the figure below:\n",
    "\n",
    "<img src=\"figures/bias-variance-diagnosis.png\" alt=\"bias-variance-diagnosis\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "## 2.4. Bias & variance correction\n",
    "\n",
    "In the previous section, we saw how looking at training error and validation error can help you diagnose whether your algorithm has a bias or a variance problem, or maybe both. Knowing whether your model is overfitting or underfitting your data helps you take the correct measures in order to improve your algorithms' performance systematically.\n",
    "\n",
    "If your algorithm has a high bias, the following are some of the possible remedies:\n",
    "* Try to make your model more complex\n",
    "* Add more features if possible\n",
    "* Try a different model that is suitable for your data.\n",
    "* Train your model longer.\n",
    "\n",
    "On the other hand, if your algorithm has a high variance, you can:\n",
    "* Get more data.\n",
    "* Use regularization.\n",
    "* Try a different model that is suitable for your data.\n",
    "\n",
    "<img src=\"figures/bias-variance-tradeoff.jpeg\" alt=\"bias-variance\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Regularization\n",
    "\n",
    "Consider the problem of predicting $y$ from $x \\in R$. The left most figure below shows the result of fitting a $y = \\theta_0+\\theta_1 x$ to a dataset. We see that the data doesn’t really lie on straight line, and so the fit is not very good.\n",
    "\n",
    "Instead, if we had added an extra feature $x^2$, and fit $y = \\theta_0 + \\theta_1 x + \\theta_1 x^2$, then we obtain a slightly better fit to the data (See middle figure). Naively, it might seem that the more features we add, the better. However, there is also a danger in adding too many features: The rightmost figure is the result of fitting a 5^{th} order polynomial:\n",
    "\n",
    "\\begin{equation}\n",
    "h_{\\theta}(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4 + \\theta_5 x^5  \n",
    "\\end{equation}\n",
    "\n",
    "We see that even though the fitted curve passes through the data perfectly, we would not expect this to be a very good predictor. This is a problem of **overfitting**.\n",
    " \n",
    "<img src=\"figures/reg_example.png\" alt=\"reg-example\" style=\"width: 700px;\"/>\n",
    "  \n",
    "If we have overfitting from our hypothesis function, we can reduce the weight that some of the terms in our function carry by increasing their corresponding cost. Let's suppose we want to reduce the influence of $\\theta_4 x^4$ and $\\theta_5 x^5$. Without actually getting rid of these features or changing the form of our hypothesis, we can instead modify our cost function, and the optimisation problem becomes:\n",
    "  \n",
    "\\begin{equation}\n",
    "\\min_{\\theta} \\dfrac {1}{2m} \\sum _{i=1}^m \\left (h_\\theta (x_{i}) - y_{i} \\right)^2 + 1000 \\times \\theta_4^2 + 1000 \\times \\theta_5^2\n",
    "\\end{equation}\n",
    "\n",
    "The reason we've added two extra terms at the end is to inflate the cost of $\\theta_4$ and $\\theta_5$ in order to reduce the impact of the correponding features. Now, in order for the cost function to get close to zero, we will have to reduce the values of $\\theta_4$ and $\\theta_5$. As a result, we may see that the new hypothesis fits the data better.\n",
    " \n",
    "We could also **regularize** all of our $\\theta$ parameters in a single summation as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{\\theta} \\dfrac {1}{2m} \\sum _{i=1}^m \\left (h_\\theta (x_{i}) - y_{i} \\right)^2 + \\lambda \\sum_{j=1}^n \\theta_j^2\n",
    "\\end{equation}\n",
    "\n",
    " \n",
    "The $\\lambda$, or lambda, is the **regularization parameter**. It determines how much the costs of our $\\theta$ parameters are inflated.\n",
    "\n",
    "Using the above cost function with the extra summation, we can smooth the output of our hypothesis function to reduce overfitting. If $\\lambda$ is chosen to be too large, it may smooth out the function too much and cause underfitting. \n",
    "\n",
    "There are many other regularization techniques, this one is known as the L2 regularization. Other Regularization types include: \n",
    "\n",
    "* Early Stopping\n",
    "* Parameter Norm Penalties \n",
    "    * L1 regularization\n",
    "    * L2 regularization\n",
    "    * Max-norm regularization\n",
    "    * Dropout regularization\n",
    "* Dataset Augmentation\n",
    "* Noise Robustness (Dropout..)\n",
    "* Sparse Representations\n",
    "* ...\n",
    "\n",
    "For more information, you can [check this article](https://medium.com/inveterate-learner/deep-learning-book-chapter-7-regularization-for-deep-learning-937ff261875c)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Regularization in  Regression Models\n",
    "\n",
    "As we add more and more parameters to our model, its complexity increases, which results in increasing variance and decreasing bias, i.e., **overfitting**.\n",
    "\n",
    "In the precedent section, we have seen that in order to overcome underfitting or high bias, we can basically add new parameters to our model so that the model complexity increases, and thus reducing high bias. Now, how can we overcome overfitting for a regression model?\n",
    "\n",
    "Basically there are two methods to overcome overfitting,\n",
    "\n",
    "* Reduce the model complexity\n",
    "* **Regularization**\n",
    "\n",
    "As we have seen before, in regularization, the cost function is penalized in order to reduce the values of our model parameters. A regularized regression cost function can then take the following form:\n",
    "\n",
    "$$ J(\\theta_0,\\theta_1)\\ =\\ \\frac{1}{2m}\\sum_{i=1}^m (\\theta_0+\\theta_1x_i-y_i)^2 + P(\\lambda,\\theta)$$\n",
    "\n",
    "We have different types of regression techniques that uses regularization to overcome this problem. \n",
    "\n",
    "### 2.6.1. Ridge Regression\n",
    "\n",
    "In Ridge Regression, the loss function is augmented in such a way that we not only minimize the sum of squared residuals but also penalize the size of parameter estimates, in order to shrink them towards zero:\n",
    "\n",
    "$$ J(\\theta)\\ =\\ \\frac{1}{2m}\\sum_{i=1}^m (h(x_i)-y_i)^2 +\\ \\lambda\\sum_{j=1}^n\\theta_j^2$$\n",
    "\n",
    "Here if you notice, we come across an extra term, which is known as the penalty term. By changing the values of $\\lambda$ (the regularization coefficient), we are basically controlling the penalty term. Higher the values of $\\lambda$, bigger is the penalty and therefore the magnitude of coefficients are reduced.\n",
    "\n",
    "Important Points about Ridge Regression:\n",
    "\n",
    "* It shrinks the parameters, therefore it is mostly used to prevent multicollinearity.\n",
    "* It reduces the model complexity by coefficient shrinkage.\n",
    "* It uses $L_2$ regularization technique. \n",
    "\n",
    "### 2.6.2. Lasso Regression\n",
    "\n",
    "The mathematics behind Lasso regression is quite similar to that of Ridge. The only difference being instead of adding squares of $\\theta$, we will add the absolute value of $\\theta$.\n",
    "\n",
    "$$ J(\\theta)\\ =\\ \\frac{1}{2m}\\sum_{i=1}^m (h(x_i)-y_i)^2 +\\ \\lambda\\sum_{j=1}^n|\\theta_j|$$\n",
    "\n",
    "Important Points about Lasso Regression:\n",
    "\n",
    "* It uses $L_1$ regularization technique \n",
    "* It is generally used when we have a high number of features, because it automatically does feature selection.\n",
    "\n",
    "### 2.6.3. Reguralization for Sparsity \n",
    "\n",
    "Let us try to visualize the effect of $L_1$ and $L_2$ regularization by plotting them. For making visualization easy, let us plot them in 2D space. For that we suppose that we just have two parameters $\\theta_0$ and $\\theta_1$. \n",
    "\n",
    "The regularization forces the model optimisation to find the best trade-off between the initial cost function and the complexity of the model represented by the penalty/regularization term $P(\\lambda,\\theta)$.\n",
    "\n",
    "In other words, if we keep the regularization term $P(\\lambda,\\theta)$ smaller than certain value, we've achieved our goal. Now let's visualize what it means for the $L_2$ norm of our weight vector to be under certain value, let's say 1. Since $L_2$ is the Euclidean distance from the origin, our desired vector should then be bound within a circle with a radius of 1, centered on the origin. \n",
    "\n",
    "This was great at keeping weights small, but it can leave the model unnecessarily large and complex, since all of the features may still remain even with small weights.\n",
    "\n",
    "When trying to keep $L_1$ norm under certain value, the area in which our weight vector can reside will take the shape of the diamond shown below. The most important takeaway here is that, when applying $L_1$ regularization, the optimal value of certain weights can end up being zero, and that's because of the extreme diamond shape of this optimal region. Thus as opposed to the smooth circular shape in $L_2$ regularization.\n",
    "\n",
    "This property of $L_1$ regularization is extensively used as a feature selection mechanism. This acts as a built-in feature selector by killing all bad features and leaving only the strongest in the model. This has many benefits especially with sparse features. With fewer coefficients to store and load, there is a reduction in storage and memory needed with a much smaller model size, which is especially important for embedded models. \n",
    "\n",
    "<img src=\"figures/Ridge_vs_Lasso_Regression.png\" alt=\"Ridge_vs_Lasso_Regularization\" style=\"width: 600px;\"/>\n",
    "\n",
    "Actually, there are different possible choices of regularization with different choices of order of the parameter in the regularization term, which is denoted by $\\sum_{j=1}^n|\\theta_j|^p$ This is more generally known as $L_p$ regularizer. The $L_0$ for $p=0$ norm is the count of the non-zero values in a vector, and the L-infinity norm for $p \\to \\infty$ the maximum absolute value of any value in a vector.\n",
    "\n",
    "\\begin{align*}\n",
    "L_0 \\text{-norm} &= \\lVert \\boldsymbol{\\theta} \\rVert_0 = \\sum_{j=0}^n |\\theta_j|^0 \\newline\n",
    "L_1 \\text{-norm} &= \\lVert \\boldsymbol{\\theta} \\rVert_1 = \\sum_{j=0}^n |\\theta_j| \\newline\n",
    "L_2 \\text{-norm} &= \\lVert \\boldsymbol{\\theta} \\rVert_2 = \\sum_{j=0}^n |\\theta_j|^2 \\newline\n",
    "L_{\\infty} \\text{-norm} &= \\lVert \\boldsymbol{\\theta} \\rVert_{\\infty} = max\\big\\{|\\theta_0|,|\\theta_1|, ..., |\\theta_n|\\big\\} \\newline\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "### 2.6.4. Elastic Net Regression\n",
    " \n",
    "In practice, usually the $L_2$-norm provides more generalizable models than the $L_1$-norm. However, in some situations, we will end up with much more complex heavy models if we use $L_2$ instead of $L_1$. This happens because often features have high correlation with each other, and the $L_1$ regularization uses one of them and throw away the other, whereas $L_2$\n",
    "regularization will keep both features and keep their weight magnitudes small. Therefore, with $L_1$, you can end up with a smaller model but it may be less predictive. \n",
    "\n",
    "To get the best of both worlds, a third commonly used model of regression is the Elastic Net which incorporates penalties from both $L_1$ and $L_2$ regularization. This way, you get the benefits of sparsity for really poor predictive features while also keeping decent and great features with smaller weights to provide a good generalization. The only trade off now is that there are two instead of one hyperparameters to tune with the two different $\\lambda$ regularization parameters.\n",
    "\n",
    "$$ J(\\theta)\\ =\\ \\frac{1}{2m}\\sum_{i=1}^m (h(x_i)-y_i)^2 +\\ \\lambda_1\\sum_{j=1}^n|\\theta_j|+\\ \\lambda_2\\sum_{j=1}^n\\theta_j^2$$\n",
    "\n",
    "Another way to write the cost function in Elastic Net includes having a regularization parameter $\\lambda$ and another parameter $\\alpha$ corresponding to the weight of $L_1$ and $L_2$ penalty in your cost function:\n",
    "\n",
    "$$ J(\\theta)\\ =\\ \\frac{1}{2m}\\sum_{i=1}^m (h(x_i)-y_i)^2 +\\ \\lambda( \\frac{1-\\alpha}{2}\\sum_{j=1}^n\\theta_j^2 + \\alpha \\sum_{j=1}^n|\\theta_j| ) $$\n",
    "\n",
    "Therefore, in addition to setting and choosing a $\\lambda$ value, elastic net also allows us to tune the $\\alpha$ parameter where $\\alpha = 0$ corresponds to ridge and $\\alpha = 1$ to lasso. Simply put, if you plug in $0$ for $\\alpha$, the penalty function reduces to the $L_1$ (ridge) term and if we set $\\alpha$ to $1$ we get the $L_2$ (lasso) term. Therefore we can choose an alpha value between 0 and 1 to optimize the elastic net. Effectively this will shrink some coefficients and set some to 0 for sparse selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Learning curves\n",
    "\n",
    "Learning curves are often a very useful thing to plot. If either you wanted to sanity check that your algorithm is working correctly, or if you want to improve the performance of the algorithm.\n",
    "\n",
    "Learning Curve Theory:\n",
    "\n",
    "* Graph that compares the performance of a model on training and testing data over a varying number of training instances\n",
    "* We should generally see performance improve as the number of training points increases\n",
    "* When we separate training and testing sets and graph them individually\n",
    "    * We can get an idea of how well the model can generalize to new data\n",
    "* Learning curve allows us to verify when a model has learned as much as it can about the data, when it occurs\n",
    "    * The performances on the training and testing sets reach a plateau\n",
    "    * There is a consistent gap between the two error rates\n",
    "* The key is to find the sweet spot that minimizes bias and variance by finding the right level of model complexity\n",
    "* Of course with more data any model can improve, and different models may be optimal\n",
    "\n",
    "Types of learning curves:\n",
    "\n",
    "* **Bad Learning Curve: High Bias**\n",
    "    - When training and testing errors converge and are high\n",
    "    - No matter how much data we feed the model, the model cannot represent the underlying relationship and has high systematic errors\n",
    "    - Poor fit\n",
    "    - Poor generalization\n",
    "* **Bad Learning Curve: High Variance**\n",
    "    - When there is a large gap between the errors\n",
    "    - Require data to improve\n",
    "    - Can simplify the model with fewer or less complex features\n",
    "* **Ideal Learning Curve**\n",
    "    - Model that generalizes to new data\n",
    "    - Testing and training learning curves converge at similar values\n",
    "    - Smaller the gap, the better our model generalizes\n",
    "    \n",
    "    \n",
    "The following example is a typical case of high variance:\n",
    "\n",
    "<img src=\"figures/learning-curve-high-variance.jpg\" alt=\"learning-curve-high-variance\" style=\"width: 500px;\"/>\n",
    "\n",
    "The following diagram is a typical case of high bias.\n",
    "\n",
    "<img src=\"figures/learning-curve-high-bias.jpg\" alt=\"learning-curve-high-bias\" style=\"width: 500px;\"/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-venv",
   "language": "python",
   "name": "dl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
