{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used cars database\n",
    "\n",
    "**Over 370,000 used cars scraped from Ebay Kleinanzeigen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/used-cars-database/autos.csv\", sep=',', header=0, encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"price\"] > 0]\n",
    "df = df[df[\"yearOfRegistration\"] > 1950]\n",
    "df = df[df[\"yearOfRegistration\"] < 2020]\n",
    "df = df[df[\"powerPS\"] >0]\n",
    "df = df[df[\"powerPS\"] <1000]\n",
    "df = df[df[\"price\"] < 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration_cols = ['yearOfRegistration', 'monthOfRegistration', 'dayOfRegistration']\n",
    "\n",
    "df['monthOfRegistration'].replace(0, 1, inplace=True)\n",
    "df['dayOfRegistration'] = 1\n",
    "\n",
    "df['dateOfRegistration'] = df[registration_cols].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)\n",
    "df['dateOfRegistration'] = pd.to_datetime(df['dateOfRegistration'])\n",
    "\n",
    "df.drop(registration_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dateCrawled'] = pd.to_datetime(df['dateCrawled'])\n",
    "df['dateCreated'] = pd.to_datetime(df['dateCreated'])\n",
    "df['lastSeen'] = pd.to_datetime(df['lastSeen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "# Dropping columns with missing value rate higher than threshold in the training set\n",
    "df = df[df.columns[df.isnull().mean() < threshold]]\n",
    "\n",
    "# Dropping rows with missing value rate higher than threshold\n",
    "df = df.loc[df.isnull().mean(axis=1) < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(value=\"<UNK>\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Distribution of the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Car Price Distribution Plot')\n",
    "sns.distplot(df.price)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Car Price Spread')\n",
    "sns.boxplot(y=df.price)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['powerPS', 'kilometer']\n",
    "fig_rows = np.ceil(len(num_cols)/2)\n",
    "\n",
    "plt.figure(figsize=(15, fig_rows*5))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for ind, col in enumerate(num_cols):\n",
    "    plt.subplot(fig_rows,2,ind+1)\n",
    "    plt.title(col+' Distribution')\n",
    "    ax = sns.distplot(df[col])\n",
    "    ax.set(xlabel = col, ylabel='Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['powerPS', 'kilometer']\n",
    "fig_rows = np.ceil(len(num_cols)/2)\n",
    "\n",
    "plt.figure(figsize=(15, fig_rows*5))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for ind, col in enumerate(num_cols):\n",
    "    plt.subplot(fig_rows,2,ind+1)\n",
    "    plt.title('price vs. '+col+' Scatter')\n",
    "    ax = sns.scatterplot(x=df[col],y=df[\"price\"])\n",
    "    ax.set(xlabel = col, ylabel='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Catagorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols =['seller', 'offerType', 'abtest', 'vehicleType', 'gearbox', 'model', 'fuelType', 'brand', 'notRepairedDamage']\n",
    "fig_rows = np.ceil(len(cat_cols)/2)\n",
    "\n",
    "plt.figure(figsize=(15, fig_rows*6))\n",
    "plt.subplots_adjust(hspace=0.7)\n",
    "\n",
    "for ind, col in enumerate(cat_cols):\n",
    "    plt.subplot(fig_rows,2,ind+1)\n",
    "    plt.title(col+' Histogram')\n",
    "    ax = sns.countplot(df[col])\n",
    "    ax.set(xlabel = col, ylabel='Frequency')\n",
    "    xtickslabels=ax.get_xticklabels()\n",
    "    ax.set_xticklabels(xtickslabels, rotation=80)\n",
    "    # reduce number of ticks when too many\n",
    "    if(len(xtickslabels)>20):\n",
    "        for ind, label in enumerate(xtickslabels):\n",
    "            if ind % 7 == 0:  # every 10th label is kept\n",
    "                label.set_visible(True)\n",
    "            else:\n",
    "                label.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.seller.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.offerType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.model.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.postalCode.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nrOfPictures.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols =['seller', 'offerType', 'abtest', 'vehicleType', 'gearbox', 'model', 'fuelType', 'brand', 'notRepairedDamage']\n",
    "fig_rows = np.ceil(len(cat_cols)/2)\n",
    "\n",
    "plt.figure(figsize=(15, fig_rows*6))\n",
    "plt.subplots_adjust(hspace=0.7)\n",
    "\n",
    "for ind, col in enumerate(cat_cols):\n",
    "    plt.subplot(fig_rows,2,ind+1)\n",
    "    plt.title('price vs ' +col+' Boxplot')\n",
    "    ax = sns.boxplot(x=df[col], y=df[\"price\"])\n",
    "    ax.set(xlabel = col, ylabel='price')\n",
    "    xtickslabels=ax.get_xticklabels()\n",
    "    ax.set_xticklabels(xtickslabels, rotation=80)\n",
    "    # reduce number of ticks when too many\n",
    "    if(len(xtickslabels)>20):\n",
    "        for ind, label in enumerate(xtickslabels):\n",
    "            if ind % 5 == 0:  # every 10th label is kept\n",
    "                label.set_visible(True)\n",
    "            else:\n",
    "                label.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dates_cols = ['dateCrawled', 'dateCreated', 'lastSeen', 'dateOfRegistration']\n",
    "fig_rows = np.ceil(len(cat_cols)/2)\n",
    "\n",
    "plt.figure(figsize=(15, fig_rows*5))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for ind, col in enumerate(dates_cols):\n",
    "    plt.subplot(fig_rows,2,ind+1)\n",
    "    plt.title(col+' Histogram')\n",
    "    ax = sns.countplot((df[col].dt.year.astype(str) + '-' + df[col].dt.month.astype(str)).sort_values())\n",
    "    ax.set(xlabel = col, ylabel='Frequency')\n",
    "    xtickslabels=ax.get_xticklabels()\n",
    "    ax.set_xticklabels(xtickslabels, rotation=80)\n",
    "    # reduce number of ticks when too many\n",
    "    if(len(xtickslabels)>20):\n",
    "        for ind, label in enumerate(xtickslabels):\n",
    "            if ind % 20 == 0:  # every 10th label is kept\n",
    "                label.set_visible(True)\n",
    "            else:\n",
    "                label.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop(\"price\")\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=8)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Removing non-predictive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.drop(['dateCrawled', 'name', 'seller', 'offerType', 'nrOfPictures', 'postalCode', 'lastSeen'], axis=1, inplace=True)\n",
    "X_test.drop(['dateCrawled', 'name', 'seller', 'offerType', 'nrOfPictures', 'postalCode', 'lastSeen'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding feature 'vehicle age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['age'] = (X_train['dateCreated'] -  X_train['dateOfRegistration'])/ np.timedelta64(1, 'Y')\n",
    "X_test['age'] = (X_test['dateCreated'] -  X_test['dateOfRegistration'])/ np.timedelta64(1, 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.title('age Distribution')\n",
    "ax = sns.distplot(X_train['age'])\n",
    "ax.set(xlabel = 'age', ylabel='Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('dateCreated', axis=1, inplace=True)\n",
    "X_test.drop('dateCreated', axis=1, inplace=True)\n",
    "X_train.drop('dateOfRegistration', axis=1, inplace=True)\n",
    "X_test.drop('dateOfRegistration', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating polynomial features for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['kilometer', 'powerPS', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PF = PolynomialFeatures(degree=4, include_bias=False)\n",
    "\n",
    "# Encode categorical columns, and store results in a new dataframe\n",
    "X_train_poly = pd.DataFrame(PF.fit_transform(X_train[num_cols]), index=X_train.index)\n",
    "X_test_poly = pd.DataFrame(PF.transform(X_test[num_cols]), index=X_test.index)\n",
    "\n",
    "# Adding poly columns to initial datasets\n",
    "poly_feature_names = PF.get_feature_names()\n",
    "replace_dict = {\"x\"+str(i):num_cols[i] for i in range(3)}\n",
    "\n",
    "for ind, name in replace_dict.items():\n",
    "    poly_feature_names = [w.replace(ind, name) for w in poly_feature_names]\n",
    "X_train_poly.columns = poly_feature_names\n",
    "X_test_poly.columns = poly_feature_names\n",
    "\n",
    "# Drop initial columns \n",
    "X_train.drop(num_cols ,axis=1, inplace=True)\n",
    "X_test.drop(num_cols ,axis=1, inplace=True)\n",
    "num_cols = poly_feature_names\n",
    "\n",
    "# Add feature engineered columns to initial dataset\n",
    "X_train = pd.concat([X_train, X_train_poly], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_poly ], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_cols = ['mileage', 'engine_power', 'age']\n",
    "\n",
    "#for col in num_cols:\n",
    "#    X_train[col+'2'] = X_train[col]**2\n",
    "#    X_test[col+'2'] = X_test[col]**2\n",
    "#    X_train[col+'3'] = X_train[col]**3\n",
    "#    X_test[col+'3'] = X_test[col]**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Scaling numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS = StandardScaler()\n",
    "scaled_cols = num_cols \n",
    "\n",
    "X_train[scaled_cols] = SS.fit_transform(X_train[scaled_cols])\n",
    "X_test[scaled_cols] = SS.transform(X_test[scaled_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(X_test['brand'])-set(X_train['brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(X_test['model'])-set(X_train['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = LabelEncoder()\n",
    "le_cols = [] \n",
    "\n",
    "for col in le_cols:\n",
    "    # fit transform the training set\n",
    "    X_train[col] = LE.fit_transform(X_train[col])\n",
    "\n",
    "    # transform the test set\n",
    "    X_test[col] = X_test[col].map(lambda s: 'other' if s not in LE.classes_ else s)\n",
    "    le_classes = LE.classes_.tolist()\n",
    "    bisect.insort_left(le_classes, 'other')\n",
    "    LE.classes_ = le_classes\n",
    "\n",
    "    X_test[col] = LE.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. One hot encoding of other catagorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHE = OneHotEncoder(drop = None, handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# Define categorical to be one hot encoded\n",
    "ohe_cols = [\"abtest\", \"vehicleType\", \"gearbox\", \"model\", \"fuelType\", \"brand\", \"notRepairedDamage\"]\n",
    "\n",
    "# Encode categorical columns, and store results in a new dataframe\n",
    "X_train_encoded = pd.DataFrame(OHE.fit_transform(X_train[ohe_cols]), index=X_train.index)\n",
    "X_test_encoded = pd.DataFrame(OHE.transform(X_test[ohe_cols]), index=X_test.index)\n",
    "\n",
    "# Retrieve encoded columns names\n",
    "X_train_encoded.columns = OHE.get_feature_names(ohe_cols)\n",
    "X_test_encoded.columns = OHE.get_feature_names(ohe_cols)\n",
    "\n",
    "# Drop initial columns \n",
    "X_train.drop(ohe_cols ,axis=1, inplace=True)\n",
    "X_test.drop(ohe_cols ,axis=1, inplace=True)\n",
    "\n",
    "# Add encoded columns to initial dataset\n",
    "X_train = pd.concat([X_train, X_train_encoded], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_encoded ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit linear model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predicting over training & testing datasets\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = (np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeCV(alphas=[10**i for i in np.arange(-4, 4,  0.2, dtype=float)], scoring='r2', cv=5)\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# predicting over training & testing datasets\n",
    "y_train_pred = ridge.predict(X_train)\n",
    "y_test_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training the model\n",
    "param_grid = {'alpha': [10**i for i in np.arange(-4, 4,  0.2, dtype=float)]}\n",
    "\n",
    "ridge = Ridge(normalize=False)\n",
    "ridge_search = GridSearchCV(ridge, param_grid, scoring='r2', cv=5)\n",
    "ridge_search.fit(X_train, y_train)\n",
    "\n",
    "# predicting over training & testing datasets\n",
    "y_train_pred = ridge_search.predict(X_train)\n",
    "y_test_pred = ridge_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation for training set\n",
    "rmse = (np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training the model\n",
    "param_grid = {'alpha': [10**i for i in np.arange(-4, 4,  0.5, dtype=float)]}\n",
    "\n",
    "lasso = Lasso(normalize=False)\n",
    "lasso_search = GridSearchCV(lasso, param_grid, scoring='r2', cv=5)\n",
    "lasso_search.fit(X_train, y_train)\n",
    "\n",
    "# predicting over training & testing datasets\n",
    "y_train_pred = lasso_search.predict(X_train)\n",
    "y_test_pred = lasso_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation for training set\n",
    "rmse = (np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[int(x) for x in np.linspace(start = 100, stop = 400, num = 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = { # Number of trees in random forest\n",
    "               'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 400, num = 4)],\n",
    "                # Number of features to consider at every split\n",
    "               'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                # Maximum number of levels in tree\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)] + [None],\n",
    "                # Minimum number of samples required to split a node\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "                # Minimum number of samples required at each leaf node\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "                # Method of selecting samples for training each tree\n",
    "               'bootstrap': [True, False]\n",
    "              }\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "               'n_estimators': [400],\n",
    "               'max_features': ['auto', 'sqrt', 'log2'],\n",
    "               'max_depth': [5, 10, 30] + [None]\n",
    "              }\n",
    "\n",
    "print(random_grid)\n",
    "rf = RandomForestRegressor(criterion=\"mse\", random_state=0)\n",
    "rf_search = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 12, cv = 3, verbose=2, random_state=0)\n",
    "rf_search = rf_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting over training & testing datasets\n",
    "y_train_pred = rf_search.predict(X_train)\n",
    "y_test_pred = rf_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation for training set\n",
    "rmse = (np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_test_pred})\n",
    "# plot a sample of observations\n",
    "predictions = predictions.sample(n=200)\n",
    "predictions = predictions.sort_index().reset_index()\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "predictions['Actual'].plot(legend=True)\n",
    "predictions['Predicted'].plot(legend=True)\n",
    "plt.title('Actual vs. Predicted Price')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Gradient Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = { # Number of trees in random forest\n",
    "               'n_estimators': [int(x) for x in np.linspace(start = 50, stop = 400, num = 8)],\n",
    "                # Number of features to consider at every split\n",
    "               'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                # Maximum number of levels in tree\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)] + [None],\n",
    "                # Minimum number of samples required to split a node\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "                # Minimum number of samples required at each leaf node\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'learning_rate': [0.1, 1, 10],\n",
    "               'subsample': [0.5, 0.7, 0.9]\n",
    "             }\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "               'n_estimators': [500],\n",
    "               'max_features': ['auto', 'sqrt', 'log2'],\n",
    "               'max_depth': [5, 10, 30] + [None],\n",
    "               'subsample': [0.7, 1]\n",
    "              }\n",
    "\n",
    "print(random_grid)\n",
    "gb = GradientBoostingRegressor(random_state=0)\n",
    "gb_search = RandomizedSearchCV(estimator = gb, param_distributions = random_grid, n_iter = 12, cv = 3, verbose=2, random_state=0)\n",
    "gb_search = gb_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting over training & testing datasets\n",
    "y_train_pred = gb_search.predict(X_train)\n",
    "y_test_pred = gb_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# model evaluation for training set\n",
    "rmse = (np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-venv",
   "language": "python",
   "name": "dl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
